<?xml version="1.0" encoding="UTF-8"?>
<rdf:RDF
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
   xmlns:redfoot="http://redfoot.net/2005/redfoot#"
   xmlns:commands = "http://redfoot.net/2005/commands#"        
   xmlns:server = "http://redfoot.net/2005/server#"        
>

  <redfoot:Kernel rdf:about="#">
    <rdfs:label>Redfoot Kernel</rdfs:label>
    <rdfs:comment>
    </rdfs:comment> 
    <redfoot:program rdf:resource="programs/command_runner#"/>
    <commands:config rdf:resource="commands/manage#config"/>
    <commands:config rdf:resource="commands/static#config"/>
    <server:server rdf:resource="modules/server#twisted"/>
    <server:handler rdf:resource="handlers/page#"/>
    <rdf:value rdf:datatype="http://redfoot.net/2005/redfoot#Python">
<![CDATA[

"""
Redfoot an application for managing and running hypercode. And includes hypercode for building websites.

For help on Redfoot see:

   redfoot.py help

"""

import sys, getopt

import traceback
from types import ModuleType
from urlparse import urljoin, urldefrag
from urllib import pathname2url, url2pathname
from itertools import chain
import os

logging = redfoot_loader.log

root = logging.getLogger()
#root.setLevel(logging.DEBUG)

from rdflib import RDF, RDFS, Namespace, StringInputSource
from rdflib import Graph, URIRef, BNode, Literal
from rdflib.util import first, date_time
import urllib2, re

NAMESPACE = URIRef("http://redfoot.net/2005/redfoot#")

DC_creator = URIRef("http://purl.org/dc/elements/1.1/creator")
DC_created = URIRef("http://purl.org/dc/terms/created")

HTTP = Namespace("http://www.w3.org/1999/xx/http#")
OWL = Namespace("http://www.w3.org/2002/07/owl#")
SCUTTER = Namespace("http://redfoot.net/2006/scutter#")

LINK_PREDICATES = [OWL.imports,RDFS.isDefinedBy,RDFS.seeAlso]

HTTP_CACHE_PREDICATES = [
    HTTP['Date'],
    HTTP['Last-Modified'],
    HTTP['Content-Type'],
    HTTP['ETag'],
]

HEADER_KEYS = [
    'Date',
    'Last-Modified',
    'Content-Type',
    'ETag',
]

SCUTTER_STEPS = 5

class HTTPGetEvent:
    """
    Represents a prior HTTP GET by a scutter (a dated event).  Provides functionality for
    managing HTTP headers for subsequent fetches (to the same location)
    """
    def __init__(self,provenanceGraph,location,log,eventId=None):
        self.log = log
        if eventId:
            assert isinstance(eventId,BNode)
            self.identifier = eventId
        else:
            event = first(provenanceGraph.subjects(SCUTTER.fetch,URIRef(location)))
            
            if event:
                self.identifier = event
            else:
                self.identifier = BNode()
                provenanceGraph.add((self.identifier,SCUTTER.fetch,URIRef(location)))
                provenanceGraph.add((self.identifier,RDF.type,SCUTTER.Event))
                provenanceGraph.add((self.identifier, DC_created, Literal(date_time())))
            
        self.provenanceGraph = provenanceGraph

    def cacheEvent(self,httpStream,parseFormat):
        """
        Cache HTTP header information from the given HTTP stream
        parseFormat is the format (xml or n3) that was used to successfully parse
        the RDF graph and is used as a fallback if the content-type doesn't match (text/plain, for instance)
        """
        #self.log.info("Caching HTTP headers for URL: %s"%(first(self.provenanceGraph.objects(self.identifier,SCUTTER.fetch))))
        for header_key in HEADER_KEYS:
            val = httpStream.info().get(header_key)
            if header_key == 'Content-Type':
                isXml = re.match(r'(?:text|application)/.*\+?xml',val) is not None
                if not isXml and parseFormat=='n3':
                    val = 'text/n3'
                elif not isXml and parseFormat=='xml':
                    val = 'application/rdf+xml'
                
            if val:
                #self.log.info("Caching HTTP header (%s): %s"%(header_key,val))
                self.provenanceGraph.add((self.identifier,HTTP[header_key],Literal(val)))

    def invalidateCache(self):
        """
        Clear the HTTP header metadata associated with this event. This would be called if
        the content at the location was updated
        """
        for http_cache_pred in HTTP_CACHE_PREDICATES:
            self.provenanceGraph.remove((graph.identifier,http_cache_pred,None))

    def createHTTPHeaders(self):
        """
        Return a dictionary of HTTP headers to be used for a subsequent fetch to
        the location associated with this event.  This is mechanism by which
        HTTP caching and content negotiation is faciliated
        """
        headers={}        
        httpDate = first(self.provenanceGraph.objects(self.identifier,HTTP['Date']))
        httpLastModified = first(self.provenanceGraph.objects(self.identifier,HTTP['Last-Modified']))
        httpContentType = first(self.provenanceGraph.objects(self.identifier,HTTP['Content-Type']))
        httpETag = first(self.provenanceGraph.objects(self.identifier,HTTP['ETag']))

        if httpDate:
            headers['If-Modified-Since']= httpDate
            
        if httpETag:
            headers['If-None-Match']    = httpETag

        headers['Accept']               = httpContentType
        headers['User-agent']           = 'Redfoot 2.0.X'

        isXml = re.match(r'(?:text|application)/.*\+?xml',httpContentType) is not None

        return headers, isXml and 'xml' or 'n3'

class Redfoot(Graph):

    def __init__(self, backend):
        super(Redfoot, self).__init__(backend)
        self.scutterFailureCache = {}
	self.__base = None # default to CWD
        self.__log = None        
        self.__index = None
        self.__config = None
        # Note: we are currently being passed an open backend        
        global REDFOOT
        # bootstraping REDFOOT namespace        
        if not (NAMESPACE, None, None) in self:
            context = Graph()
            context.load(NAMESPACE)
        else:
            context = super(Redfoot, self).get_context(self.context_id(NAMESPACE))
            #context = self.get_context(self.context_id(NAMESPACE))            
        REDFOOT = self.namespace(NAMESPACE, context)
        self.check(NAMESPACE)
        
        self.uri = redfoot_program # uri to the version of redfoot that's running
        context = dict({"redfoot": self, "REDFOOT": REDFOOT, 
                        "RDF": RDF, "RDFS": RDFS,
                        "URIRef": URIRef, "BNode": BNode, "Literal": Literal
                        })
        self.__context = context
        
    def absolutize(self, uri, defrag=1):
        base = self.base
        result = urljoin(base, uri, allow_fragments=not defrag)
        if not defrag:
            if uri and uri[-1]=="#" and result[-1]!="#":
                result = "%s#" % result
        else:
            result, frag = urldefrag(result)
        return URIRef(result)

    def __get_base(self):
        if self.__base is None:
            self.__base = self.value(REDFOOT.Globals, REDFOOT.base)
            if self.__base is None:
                self.__base = URIRef("%s/" % urljoin("file:", pathname2url(os.getcwd())))
        return self.__base
    def __set_base(self, base):
	self.remove((REDFOOT.Globals, REDFOOT.base, None))
	self.add((REDFOOT.Globals, REDFOOT.base, base))
    base = property(__get_base, __set_base)

    def _get_log(self):
        if self.__log is None:
            self.__log = logging
        return self.__log
    log = property(_get_log)

    def __get_program(self):
        # redfoot_program is defined by the BootLoader and is the boot program
        program = self.value(redfoot_program, REDFOOT.program)
        assert program, "No default program found"            
        return program
    # program resource redfoot will execute
    program = property(__get_program)
    
    def __get_config(self):
        config = self.__config
        if config is None:
           config =  self.__config = self.get_context(BNode("_config"), creator=redfoot_loader.program)
        return config
    # context where redfoot stores configuration data
    config = property(__get_config)

    def __get_index(self):
        index = self.__index
        if index is None:
            id = BNode("_index")
            # To avoid recursion we call get_context on super then
            # call get_context on self
            index = self.__index = super(Redfoot, self).get_context(id) 
            self.get_context(id, creator=redfoot_loader.program)  
        return index
    # context where redfoot stores data about contexts
    index = property(__get_index)
            
    def open(self, path):
        super(Redfoot, self).open(path)

    def label(self, subject, default=''):
        # TODO: push this subproperty support back down into rdflib
        label = super(Redfoot, self).label(subject, None)
        if label is None:
            for subproperty in self.transitive_subjects(RDFS.subPropertyOf, RDFS.label):
                label = self.value(subject, subproperty, default=None, any=True)        
                if label is not None:
                    return label
        return label or default

    def check(self, uri, publicID=None):
        """
        Checks to see if redfoot knows anything about uri

        Currently, if not, Redfoot will attempt to load from uri.
        """
        location = uri
        uri = publicID or uri
        if isinstance(uri, URIRef):
            context_uri = self.context_id(uri)
            if not (uri, None, None) in self:
                if not (REDFOOT.Checked, RDFS.member, context_uri) in self: 
                    self.index.add((REDFOOT.Checked, RDFS.member, context_uri))
                    if uri==location:
                        self.log.info("loading: %s" % uri)
                    else:
                        self.log.info("loading: %s from %s" % (publicID, location))
                    try:
                        context = self.load(location, publicID=publicID, creator=redfoot_loader.program)
                    except Exception, e:
                        self.log.warning("couldn't load %s while checking: %s\n" % (uri, e))

    def scutter(self, location, creator, steps=SCUTTER_STEPS):
        """
        Performs a recursive scutter from the given location.  This assumes that the location has already
        been loaded / cached prior to this function being called.  It attempts to load references (via link predicates)
        as URLs, recursively (breadth-first) calling scutter on each URL that was successfully loaded as an RDF graph .  It does
        this no more than SCUTTER_STEPS times.  Content negotiation is used to perform discovery of uknown URLs in order
        to determine how to parse remote content.
        """
        self.log.info("Scuttering from %s"%location)
        visitedNodes = []
        for linkPredicate in LINK_PREDICATES:
            sourceGraph = self.get_context(self.context_id(location),creator=creator)
            for linkURL in sourceGraph.objects(None,linkPredicate):
                #If the link is to itself or it has been attempted before, ignore
                if linkURL == location or linkURL in self.scutterFailureCache:
                    continue
                #Skip the rest if the maximum number of recursion steps have been surpassed
                if steps < 1:
                    break
                
                #Check if linkURL has already been loaded
                priorEvent = first(self.index.subjects(SCUTTER.fetch,linkURL))
                if priorEvent:
                    #Aleady loaded, attempt a cacheable, content-negotiated load with HTTP provenance data on RDF graph URL
                    priorEvent = HTTPGetEvent(self.index,linkURL,self.log,priorEvent)
                    hdrs,format = priorEvent.createHTTPHeaders()
                    try:
                        httpStream = urllib2.urlopen(urllib2.Request(linkURL,headers=hdrs))
                        rt = httpStream.read()
                        self.log.info("URL %s (linked by %s) already loaded previously, but content has changed since .."%(linkURL,linkPredicate))
                        #Fresh content since last fetch, need to update HTTP cache provenance and refresh graph
                        priorEvent.invalidateCache()
                        graph = self.get_context(self.context_id(linkURL))
                        graph.remove((None,None,None))
                        graph.load(StringInputSource(rt),format=format)
                        priorEvent.cacheEvent(httpStream,format)
                    except urllib2.HTTPError, e:
                        assert e.code == 304
                        #HTTP Error 304: Not Modified, do nothing
                else:
                    #self.log.info("URL %s (linked by %s) has not been loaded before.. Attempting RESTful discovery"%(linkURL,linkPredicate))
                    #Hasn't been loaded.  Need to perform 'RESTful' scutter discovery
                    #Try to connect, first
                    try:
                        httpStream = urllib2.urlopen(linkURL)
                    except Exception, e:
                        self.log.warning("Unable to connect to %s: %s\n"%(linkURL,e))
                        continue
                    
                    contentType = httpStream.info().get('content-type')

                    #Ignore HTML content type (XHTML or otherwise)
                    if re.match(r'.*html',contentType) is not None:
                        self.scutterFailureCache[linkURL]=None
                        continue
                    isXml = re.match(r'(?:text|application)/.*\+?xml',contentType) is not None
                    
                    try:
                        #Trying Notation 3 parse first, unless content-type header specifies it is
                        #RDF/XML or N3 parse fails
                        if isXml:
                            raise Exception("Not Notation 3 (%s)"%contentType)

                        self.log.info("Non-XML content, attempting Notation parse")

                        graph = super(Redfoot, self).get_context(self.context_id(linkURL))
                        graph.load(httpStream,format='n3')
                        #Successfully performed Notation 3 parse, persist HTTP headers (and other provenance data) and setup for next recursion
                        graph = self.get_context(self.context_id(linkURL),creator=creator)
                        graph.remove((context_id, REDFOOT.source, None))
                        graph.add((context_id, REDFOOT.source, location))
                        
                        newEvent = HTTPGetEvent(self.index,linkURL,self.log)
                        newEvent.cacheEvent(httpStream,'n3')
                        visitedNodes.append(linkURL)
                        steps -= 1
                        
                    except:
                        #import traceback
                        #traceback.print_exc()
                        #Attempt to parse as RDF/XML instead (send accept header of 'application/rdf+xml')
                        #self.log.info("Attempting RDF/XML parse")
                        try:
                            context_id = self.context_id(linkURL)
                            graph = self.get_context(context_id,creator=creator)
                            graph.load(httpStream)
                            #Successfully performed RDF/XML persist HTTP headers (and other provenance data) and setup for next recursion
                            graph.remove((context_id, REDFOOT.source, None))
                            graph.add((context_id, REDFOOT.source, location))
                            
                            newEvent = HTTPGetEvent(self.index,linkURL,self.log)
                            newEvent.cacheEvent(httpStream,'xml')
                            visitedNodes.append(linkURL)
                            steps -= 1

                        except Exception, e:
                            self.log.warning("Unable to parse %s as either N3 or RDF/XML: %s"%(linkURL,e))
                            self.scutterFailureCache[linkURL]=None
                            
        for visitedLocation in visitedNodes:
            self.scutter(visitedLocation,creator,steps=steps)

    def load(self, location, format="xml", publicID=None, creator=None):
        """
        location is a relative or absolute URI
        publicID if specified will override location as the xml:base
        contextID
        """
        publicID = publicID or self.absolutize(location)
        publicID = self.absolutize(publicID, defrag=False)
        context_id = self.context_id(publicID)
        context = self.get_context(context_id, creator=creator)
        priorEvent = first(self.index.subjects(SCUTTER.fetch,location))
        if priorEvent:
            self.log.info("HTTP provenance metadata exists for %s.  Attempting RESTful HTTP request "%location)
            #Aleady loaded, attempt a cacheable, content-negotiated load with HTTP provenance data on RDF graph URL
            priorEvent = HTTPGetEvent(self.index,location,self.log,priorEvent)
            hdrs,format = priorEvent.createHTTPHeaders()

            try:
                httpStream = urllib2.urlopen(urllib2.Request(location,headers=hdrs))
                rt = httpStream.read()
                self.log.info("Fresh content (%s bytes) loaded (modified since last attempt)"%(len(rt)))
                #Fresh content since last fetch, need to update HTTP provenance and reload graph
                priorEvent.invalidateCache()
                context.remove((None,None,None))
                graph.load(StringInputSource(rt),format=format)
                priorEvent.cacheEvent(httpStream,format)

            except urllib2.HTTPError, e:
                self.log.info("Recieved 304 status from server.  Cached content is sufficient")
                assert e.code == 304
                #HTTP Error 304: Not Modified, do nothing

            #Scutter from location
            self.scutter(location,creator)
            
        else:
            context.remove((None, None, None))
            context.load(location, publicID=publicID, format=format)
            try:
                httpStream = urllib2.urlopen(urllib2.Request(location))
                #Content was loaded via HTTP, cache HTTP headers and attempt to scutter
                self.log.info("New RDF Graph loaded over HTTP from %s"%location)
                newEvent = HTTPGetEvent(self.index,location,self.log)
                newEvent.cacheEvent(httpStream,format)

            except Exception, e:
                raise
                self.log.warning(repr(e))
                #Content wasn't loaded via HTTP, no header cache
                pass

        self.index.remove((context_id, REDFOOT.source, None))
        self.index.add((context_id, REDFOOT.source, location))
        self.index.remove((context_id, REDFOOT.publicID, None))        
        self.index.add((context_id, REDFOOT.publicID, publicID))
        self.scutter(location,creator)
        return context

    def get_context(self, identifier, creator=None):
        """ Returns a Context graph for the given identifier, which
        must be a URIRef or BNode."""
        result = super(Redfoot, self).get_context(identifier)
        self.index.remove((identifier, RDF.type, REDFOOT.DeletedContext))
        self.index.add((identifier, RDF.type, REDFOOT.Context))
        if creator and not (identifier, DC_creator, None) in self.index:
            self.index.add((identifier, DC_creator, creator))
            self.index.add((identifier, DC_created, Literal(date_time())))
        return result

    def remove_context(self, identifier):
        """removes both the context and metadata about the context."""
        self.index.remove((identifier, None, None))
        self.index.add((identifier, RDF.type, REDFOOT.DeletedContext))        
        super(Redfoot, self).remove_context(identifier)

    def module(self, subject):
        subject = URIRef(subject)
        if not (subject, None, None) in self:
            self.log.info("importing: %s" % subject)
            try:
                self.load(subject, creator=redfoot_loader.program)
            except Exception, e:
                raise Exception("Error trying to load module for %s\n%s" % (subject, e))
                
        value = self.value(subject)
        assert value!=None, "No objects found for %s, %s" % (subject, RDF.value)

        module_name = subject
        safe_module_name = "subject_%s" % hash(subject)

        module = sys.modules.get(module_name, None)
        if module:
            return module

        module = ModuleType(safe_module_name)
        module.__name__ = module_name 
        module.__file__ = subject
        module.__ispkg__ = 0
        sys.modules[module_name] = module
        code = compile(value+"\n", subject, "exec")
        for key, value in self.__context.items():
            module.__dict__[key] = value
        module.__dict__["__uri__"] = subject

        exec code in module.__dict__
        return sys.modules[module_name]

    def execute(self, code, context=None, **args):
        self.check(code)
        value = self.value(code)
        assert value, "%s has no RDF.value" % code
        assert value.datatype==REDFOOT.Python, "%s RDF.value is not of datatype REDFOOT.Python. %s currently only supports REDFOOT.Python code values" % (code, redfoot_program)
        if context==None:
            context = dict(self.__context)
        for k, v in args.items():
            context[k] = v
        context["redfoot_current"] = code
        context["redfoot_program"] = redfoot_program

        value = value.replace("\r\n", "\n")        
        value = value.replace("\r", "\n")        
        try:
            c = compile(value+"\n", code, "exec")
            exec c in context
        except Exception, e:
            self.log.exception("While trying to exec %s the following exception occurred:\n" % code)
        return context

    def context_id(self, uri, context_id=None):
        """ URI#context """
        uri, frag = urldefrag(uri)
        frag = context_id or frag or "context"
        if frag.startswith("#"):
            frag = frag[1:]
        return URIRef("%s#%s" % (uri, frag))

    def namespace(self, uri, context=None):
        uri = URIRef(uri)
        module = sys.modules.get(uri, None)
        if module is None:
            module = sys.modules[uri] = ModuleType("namespace_%s" % hash(uri))
            module.__name__ = uri 
            module.__file__ = uri
            module.__ispkg__ = 0
            if context is None:
                self.check(uri)
                context_uri = self.context_id(uri)            
                context = self.get_context(context_uri, creator=redfoot_loader.program)            
            d = module.__dict__
            d["NS"] = uri
            # TODO: module.__getattribute__ = module.__dict__.__getitem__ 
            for subject in set(context.subjects(None, None)):
                if subject.startswith(uri):
                    ns, qname = subject.split(uri)
                    d[qname] = subject
        return module

    def bind(self, prefix, namespace, override=True):
        """
        Override Graphs bind to additionally declare the namespace to
        be of RDF.type REDFOOT.Namespce. And to load it if it's not
        already been loaded.
        """
        namespace = URIRef(namespace)
        if not (namespace, RDF.type, REDFOOT.Namespace) in self.index:
            self.check(namespace)             
            self.index.add((namespace, RDF.type, REDFOOT.Namespace))
        super(Redfoot, self).bind(prefix, namespace, override)


    def subclasses(self, uri):
        """
        Applies brute force RDFS entailment to infer additional classification 
        """
        if uri==RDFS.Resource:
            for subclass in self.subjects(RDF.type, RDFS.Class):
                for c in self.objects(subclass, RDFS.subClassOf):
                    if c==RDFS.Resource or not (c, RDF.type, RDFS.Class) in self:
                        yield subclass
                        break
            return
        for subclass in self.subjects(RDFS.subClassOf, uri):
            yield subclass

    def instances(self, uri):
	for instance in self.subjects(RDF.type, uri):
	    yield instance

    def types(self, subject):
	"""
        generator over the types of subject ordered from most specific to least
        Applies brute force RDFS entailment to infer additional classification
        """
	seen = set()
	l = []
	for type in self.objects(subject, RDF.type):
	    for t in self.transitive_objects(type, RDFS.subClassOf):
		num = len(list(self.transitive_objects(t, RDFS.subClassOf)))
		if t not in seen:
		    seen.add(t)
		    l.append((num, t))
        if isinstance(subject, URIRef):
            for type in self.objects(subject.abstract(), RDF.type):
                for t in self.transitive_objects(type, RDFS.subClassOf):
                    num = len(list(self.transitive_objects(t, RDFS.subClassOf)))
                    if t not in seen:
                        seen.add(t)
                        l.append((num, t))
	l.sort()
	l.reverse()
	for num, type in l:
	    yield type

    def possible_properties(self, type):
	for object in self.transitive_objects(type, RDFS.subClassOf):
	    for subject in self.subjects(RDFS.domain, object):
		for property in self.transitive_subjects(RDFS.subPropertyOf, subject): 
		    yield property

    def possible_properties_for_subject(self, subject):
	seen = set()
	for type in chain([RDFS.Resource], self.objects(subject, RDF.type)):
	    for property in self.possible_properties(type):
		if not property in seen:
		    seen.add(property)
		    yield property

    def main(self, options, args):
        program = self.program
        try:
            self.check(program)
        except Exception, e:
            self.log.warning("could not find program for '%s': %s" % (program, e))
        else:
            self.log.info("running: %s ( %s )" % (self.label(program), program))
            self.execute(program, args=args)

def add_func(store):
    orig_add = store.add
    def add((s, p, o), context, quoted=False):
        print "add:", s, p, o
        orig_add((s, p, o), context=context, quoted=quoted)
    return add

try:
    redfoot = redfoot_loader.redfoot
except:
    redfoot = Redfoot(redfoot_loader.backend)
    #redfoot.store.add = add_func(redfoot.store)
    redfoot_loader.redfoot = redfoot 
    # NOTE: redfoot_loader is already dealing with opening and closing the backend

from optparse import OptionParser
parser = OptionParser("usage: %prog")
parser.allow_interspersed_args = False

(options, args) = parser.parse_args(args)

redfoot.main(options, args)

]]>
    </rdf:value>
  </redfoot:Kernel>


</rdf:RDF>  
