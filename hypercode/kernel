<?xml version="1.0" encoding="UTF-8"?>
<rdf:RDF
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
   xmlns:rdfe="http://redfoot.net/rdf#"
   xmlns:redfoot="http://redfoot.net/2005/redfoot#"
   xmlns:commands = "http://redfoot.net/2005/commands#"        
   xmlns:server = "http://redfoot.net/2005/server#"        
>

  <rdfe:RDFXMLDocument rdf:about="">
    <rdfs:label>Redfoot Kernel RDF/XML</rdfs:label>
  </rdfe:RDFXMLDocument>
  
  <redfoot:Kernel rdf:about="#">
    <rdfs:label>Redfoot Kernel</rdfs:label>
    <rdfs:comment>
    </rdfs:comment> 
    <redfoot:program rdf:resource="programs/command_runner#"/>
    <commands:config rdf:resource="commands/manage#config"/>
    <commands:config rdf:resource="commands/static#config"/>
    <server:server rdf:resource="modules/server#twisted"/>
    <server:handler rdf:resource="handlers/page#"/>
    <rdf:value rdf:datatype="http://redfoot.net/2005/redfoot#Python">
<![CDATA[

"""
Redfoot an application for managing and running hypercode. And includes hypercode for building websites.

For help on Redfoot see:

   redfoot.py help

"""

import sys, getopt
import traceback
from types import ModuleType
from urlparse import urljoin, urldefrag, urlparse
from urllib import pathname2url, url2pathname
from itertools import chain
import os

logging = redfoot_loader.log

root = logging.getLogger()
#root.setLevel(logging.DEBUG)

from rdflib import RDF, RDFS, Namespace, StringInputSource
from rdflib import Graph, URIRef, BNode, Literal
from rdflib.util import first, date_time
import urllib2, re
from datetime import datetime, timedelta

NAMESPACE = URIRef("http://redfoot.net/2005/redfoot#")

DC_creator = URIRef("http://purl.org/dc/elements/1.1/creator")
DC_created = URIRef("http://purl.org/dc/terms/created")

HTTP = Namespace("http://www.w3.org/1999/xx/http#")
OWL = Namespace("http://www.w3.org/2002/07/owl#")
SCUTTER = Namespace("http://redfoot.net/2006/scutter#")

LINK_PREDICATES = [OWL.imports,RDFS.isDefinedBy,RDFS.seeAlso]

HTTP_CACHE_PREDICATES = [
    HTTP['Date'],
    HTTP['Last-Modified'],
    HTTP['Content-Type'],
    HTTP['ETag'],
]

HEADER_KEYS = [
    'Date',
    'Last-Modified',
    'Content-Type',
    'ETag',
]

SCUTTER_STEPS = 5

HTTP_CACHE_TTL = 24 * 60 * 60 #One day

class HTTPGetEvent:
    """
    Represents a prior HTTP GET by a scutter (a dated event).  Provides functionality for
    managing HTTP headers for subsequent fetches (to the same location)
    """
    def __init__(self,provenanceGraph,location,log,publicID=None,eventId=None):
        self.log = log
        if eventId:
            assert isinstance(eventId,BNode),"Scutter event identifiers should be BNodes, not %s"%(type(eventId))
            self.identifier = eventId
        else:
            event = first(provenanceGraph.subjects(SCUTTER.fetch,URIRef(location)))
            
            if event:
                self.identifier = event
            else:
                self.identifier = BNode()
                provenanceGraph.add((self.identifier,SCUTTER.fetch,URIRef(location)))
                provenanceGraph.add((self.identifier, DC_created, Literal(date_time())))
                provenanceGraph.add((self.identifier, RDF.type, SCUTTER.Event))
                if publicID:
                    provenanceGraph.add((self.identifier, SCUTTER.target, URIRef(publicID)))
                
        self.provenanceGraph = provenanceGraph

    def __get_expiration_date(self):
        now=datetime.now().isoformat().split('.')[0]
        expiration = first(self.provenanceGraph.objects(self.identifier,SCUTTER.httpCacheExpiration))
        #self.log.info(" ".join([now,expiration,str(expiration > now)]))
        return first(self.provenanceGraph.objects(self.identifier,SCUTTER.httpCacheExpiration))
    expirationDate = property( __get_expiration_date)

    def __get_public_id(self):
        return self.provenanceGraph.value(subject=self.identifier,predicate=SCUTTER.target, any=True)
    publicID = property( __get_public_id)

    def __get_system_id(self):
        return self.provenanceGraph.value(subject=self.identifier,predicate=SCUTTER.fetch, any=True)
    systemID = property(__get_system_id)        

    def cacheEvent(self,httpStream,parseFormat):
        """
        Cache HTTP header information from the given HTTP stream
        parseFormat is the format (xml or n3) that was used to successfully parse.  Setup the cache expiration
        the RDF graph and is used as a fallback if the content-type doesn't match (text/plain, for instance)
        """
        #self.log.info("Caching HTTP headers for URL: %s"%(first(self.provenanceGraph.objects(self.identifier,SCUTTER.fetch))))
        now = datetime.now()
        expirationDT = (now + timedelta(seconds = HTTP_CACHE_TTL)).isoformat().split('.')[0]
        #self.log.info(" ".join([now.isoformat(),str(HTTP_CACHE_TTL),expirationDT]))
        self.provenanceGraph.remove((self.identifier,SCUTTER.httpCacheExpiration,None))
        self.provenanceGraph.add((self.identifier, SCUTTER.httpCacheExpiration, Literal(expirationDT)))
        for header_key in HEADER_KEYS:
            val = httpStream.info().get(header_key)
            if header_key == 'Content-Type':
                isXml = re.match(r'(?:text|application)/.*\+?xml',val) is not None
                if not isXml and parseFormat=='n3':
                    val = 'text/n3'
                elif not isXml and parseFormat=='xml':
                    val = 'application/rdf+xml'
                
            if val:
                #self.log.info("Caching HTTP header (%s): %s"%(header_key,val))
                self.provenanceGraph.add((self.identifier,HTTP[header_key],Literal(val)))

    def invalidateCache(self):
        """
        Clear the HTTP header metadata associated with this event. This would be called if
        the content at the location was updated
        """
        now = datetime.now()
        expirationDT = (now + timedelta(seconds = HTTP_CACHE_TTL)).isoformat().split('.')[0]
        self.provenanceGraph.remove((self.identifier,SCUTTER.httpCacheExpiration,None))
        self.provenanceGraph.add((self.identifier, SCUTTER.httpCacheExpiration, Literal(expirationDT)))
        for http_cache_pred in HTTP_CACHE_PREDICATES:
            self.provenanceGraph.remove((self.identifier,http_cache_pred,None))

    def bumpExpiration(self):
        """
        Extend the cache expiration.  This is called because the cache expired and
        a (cacheable) subsequent request responded in a 304 (no change at the server).
        This should probably bump the cache by an increasing amount so static RDF graphs
        (like the owl.rdfs) aren't repeatably hit uneccessarily
        """
        now = datetime.now()
        expirationDT = (now + timedelta(seconds = HTTP_CACHE_TTL)).isoformat().split('.')[0]
        self.provenanceGraph.remove((self.identifier,SCUTTER.httpCacheExpiration,None))
        self.provenanceGraph.add((self.identifier, SCUTTER.httpCacheExpiration, Literal(expirationDT)))

    def createHTTPHeaders(self):
        """
        Return a dictionary of HTTP headers to be used for a subsequent fetch to
        the location associated with this event.  This is mechanism by which
        HTTP caching and content negotiation is faciliated
        """
        headers={}        
        httpDate = first(self.provenanceGraph.objects(self.identifier,HTTP['Date']))
        httpLastModified = first(self.provenanceGraph.objects(self.identifier,HTTP['Last-Modified']))
        httpContentType = first(self.provenanceGraph.objects(self.identifier,HTTP['Content-Type']))
        httpETag = first(self.provenanceGraph.objects(self.identifier,HTTP['ETag']))

        if httpDate:
            headers['If-Modified-Since']= httpDate
            
        if httpETag:
            headers['If-None-Match']    = httpETag

        headers['Accept']               = httpContentType
        headers['User-agent']           = 'Redfoot 2.0.X'

        isXml = re.match(r'(?:text|application)/.*\+?xml',httpContentType) is not None

        return headers, isXml and 'xml' or 'n3'

from urllib2 import urlopen, Request

from xml.sax.xmlreader import InputSource

from rdflib import __version__

class UnknownURLInputSource(InputSource, object):
    def __init__(self, location):
        super(UnknownURLInputSource, self).__init__(location)
        self.valid = False
        try:
            httpStream = urllib2.urlopen(urllib2.Request(location))
            self.valid = True
            self.contentType = httpStream.info().get('content-type')
            self.format = None
            if re.match(r'.*html', self.contentType) is not None:
                self.format = "html"
            elif re.match(r'(?:text|application)/.*\+?xml', self.contentType) is not None:
                self.format = "xml"
            elif re.match(r'.*n3', self.contentType) is not None:
                self.format = 'n3'
            self.setByteStream(httpStream)
        except Exception, e:
            self.log.warning("Unable to connect to %s: %s\n"%(linkURL,e))
        
class CacheableURLInputSource(InputSource, object):
    def __init__(self, priorEvent):
        super(CacheableURLInputSource, self).__init__(priorEvent.publicID)
        self.modified = True
        if priorEvent:
            hdrs, format = priorEvent.createHTTPHeaders()
            try:
                httpStream = urllib2.urlopen(urllib2.Request(system_id, headers=hdrs))
            except urllib2.HTTPError, e:
                logging.info("Recieved 304 status from server.  Cached content is sufficient")
                self.modified = False
                assert e.code == 304, "HTTP response code %s recieved after cacheable request to %s"%(e.code,self.url)
                #HTTP Error 304: Not Modified, do nothing
                httpStream = None
                # TODO: we'll likely need to deal with other http errors

        if httpStream:
            contentType = httpStream.info().get('content-type')
            format = None
            if re.match(r'.*html', contentType) is not None:
                format = "html"
            elif re.match(r'(?:text|application)/.*\+?xml', contentType) is not None:
                format = "xml"
            elif re.match(r'.*n3', contentType) is not None:
                format = 'n3'
            self.format = format
            self.setByteStream(httpStream)

    def __repr__(self):
        return self.url


class Redfoot(Graph):

    def __init__(self, backend):
        super(Redfoot, self).__init__(backend)
        self.scutterFailureCache = {}
	self.__base = None # default to CWD
        self.__log = None        
        self.__index = None
        self.__config = None
        # Note: we are currently being passed an open backend        
        global REDFOOT
        # bootstraping REDFOOT namespace        
        if not (NAMESPACE, None, None) in self:
            context = Graph()
            context.load(NAMESPACE)
        else:
            context = super(Redfoot, self).get_context(self.context_id(NAMESPACE))
            #context = self.get_context(self.context_id(NAMESPACE))            
        REDFOOT = self.namespace(NAMESPACE, context)
        self.check(NAMESPACE)
        
        self.uri = redfoot_program # uri to the version of redfoot that's running
        context = dict({"redfoot": self, "REDFOOT": REDFOOT, 
                        "RDF": RDF, "RDFS": RDFS,
                        "URIRef": URIRef, "BNode": BNode, "Literal": Literal
                        })
        self.__context = context
        
    def absolutize(self, uri, defrag=1):
        base = self.base
        result = urljoin(base, uri, allow_fragments=not defrag)
        if not defrag:
            if uri and uri[-1]=="#" and result[-1]!="#":
                result = "%s#" % result
        else:
            result, frag = urldefrag(result)
        return URIRef(result)

    def __get_base(self):
        if self.__base is None:
            self.__base = self.value(REDFOOT.Globals, REDFOOT.base)
            if self.__base is None:
                self.__base = URIRef("%s/" % urljoin("file:", pathname2url(os.getcwd())))
        return self.__base
    def __set_base(self, base):
	self.remove((REDFOOT.Globals, REDFOOT.base, None))
	self.add((REDFOOT.Globals, REDFOOT.base, base))
    base = property(__get_base, __set_base)

    def _get_log(self):
        if self.__log is None:
            self.__log = logging
        return self.__log
    log = property(_get_log)

    def __get_program(self):
        # redfoot_program is defined by the BootLoader and is the boot program
        program = self.value(redfoot_program, REDFOOT.program)
        assert program, "No default program found"            
        return program
    # program resource redfoot will execute
    program = property(__get_program)
    
    def __get_config(self):
        config = self.__config
        if config is None:
           config =  self.__config = self.get_context(BNode("_config"), creator=redfoot_loader.program)
        return config
    # context where redfoot stores configuration data
    config = property(__get_config)

    def __get_index(self):
        index = self.__index
        if index is None:
            id = BNode("_index")
            # To avoid recursion we call get_context on super then
            # call get_context on self
            index = self.__index = super(Redfoot, self).get_context(id) 
            self.get_context(id, creator=redfoot_loader.program)  
        return index
    # context where redfoot stores data about contexts
    index = property(__get_index)
            
    def open(self, path):
        super(Redfoot, self).open(path)

    def label(self, subject, default=''):
        # TODO: push this subproperty support back down into rdflib
        label = super(Redfoot, self).label(subject, None)
        if label is None:
            for subproperty in self.transitive_subjects(RDFS.subPropertyOf, RDFS.label):
                label = self.value(subject, subproperty, default=None, any=True)        
                if label is not None:
                    return label
        return label or default

    def check(self, uri):
        """
        Checks to see if redfoot knows anything about uri

        Currently, if not, Redfoot will attempt to load from uri.
        """
        if isinstance(uri, URIRef):
            location = uri.defrag()
            context_uri = self.context_id(location)
            if not (context_uri, RDF.type, REDFOOT.Context) in self.index: 
                c = self.get_context(context_uri) #self.index.add((context_uri, RDF.type, REDFOOT.Context))
                if uri==location:
                    self.log.info("loading: %s" % uri)
                else:
                    self.log.info("loading: %s from %s" % (uri, location))
                try:
                    context = self.load(location, publicID=uri, creator=redfoot_loader.program)
                except Exception, e:
                    self.log.warning("couldn't load %s while checking: %s\n" % (uri, e))

    def scutter(self, location, creator, steps=SCUTTER_STEPS):
        """
        Performs a recursive scutter from the given location.  This assumes that the location has already
        been loaded / cached prior to this function being called.  It attempts to load references (via link predicates)
        as URLs, recursively (breadth-first) calling scutter on each URL that was successfully loaded as an RDF graph .  It does
        this no more than SCUTTER_STEPS times.  Content negotiation is used to perform discovery of uknown URLs in order
        to determine how to parse remote content.
        """
        self.log.info("Scuttering from %s"%location)
        visitedNodes = []
        sourceGraph = self.get_context(self.context_id(location),creator=creator)
        for linkPredicate in LINK_PREDICATES:
            linkedURLs = []
            try:
                linkedURLs = sourceGraph.objects(predicate=linkPredicate)
            except Exception,e:
                self.log.info(e)

            for linkURL in linkedURLs:
                #If the link is to itself or it has been attempted before, ignore
                if "#" in linkURL:
                    uri, frag = urldefrag(linkURL)
                    linkURL = URIRef(uri)

                if linkURL == location or linkURL in self.scutterFailureCache:
                    continue
                #Skip the rest if the maximum number of recursion steps have been surpassed
                if steps < 1:
                    break

                #Check if linkURL has already been loaded
                priorEvent = self.index.value(predicate=SCUTTER.fetch, object=linkURL, any=True)
                if priorEvent:
                    priorEvent = HTTPGetEvent(self.index, linkURL, self.log, priorEvent)
                    if priorEvent.expirationDate < datetime.now().isoformat().split('.')[0]:
                        self.log.info("%s has already been loaded previously but the cache has expired"%linkURL)
                        #Aleady loaded, attempt a cacheable, content-negotiated load with HTTP provenance data on RDF graph URL
                        cacheableSource = CacheableURLInputSource(priorEvent)
                        if cacheableSource.modified:
                            self.load(linkURL, publicID=priorEvent.publicID,format=cacheableSource.format,scutter=False)
                        else:
                            priorEvent.bumpExpiration()
                            
                    visitedNodes.append(linkURL)
                    steps -= 1

                else:
                    #self.log.info("URL %s (linked by %s) has not been loaded before.. Attempting RESTful discovery"%(linkURL,linkPredicate))
                    #Hasn't been loaded.  Need to perform 'RESTful' scutter discovery
                    #Try to connect, first
                    unknownURL = UnknownURLInputSource(linkURL)
                    if not unknownURL.valid:
                        continue

                    #If the format is known (HTML is ignored), parse it using the format recorded at
                    #the server, otherwise ignore the URL (Perhaps this is too strict?)
                    if unknownURL.format:
                        if unknownURL.format=="html":
                            #self.log.warning("Ignoring html formatted url: %s" % (linkURL))
                            self.scutterFailureCache[linkURL]=None
                        else:
                            try:
                                self.load(linkURL, format=unknownURL.format,scutter=False)
                                visitedNodes.append(linkURL)
                                steps -= 1
                            except:
                                self.log.warning("Couldn't parse %s using the given format: %s" % (linkURL,unknownURL.format))
                                self.scutterFailureCache[linkURL]=None
                    else:
                        #Need to attempt an Notation 3 parse first, then an RDF/XML parse
                        try:
                            self.load(linkURL, format='n3',scutter=False)
                            visitedNodes.append(linkURL)
                            steps -= 1
                        except:
                            try:
                                self.load(linkURL,scutter=False)
                                visitedNodes.append(linkURL)
                                steps -= 1                                
                            except Exception,e:
                                self.log.warning("Unable to parse %s as either N3 or RDF/XML: %s" % (linkURL, e))
                                self.scutterFailureCache[linkURL]=None
                                
        visitedNodes = dict([(location,None) for location in visitedNodes]).keys()                   
        for visitedLocation in visitedNodes:
            self.scutter(visitedLocation,creator,steps=steps)

    def load(self, location, format="xml", publicID=None, creator=None, scutter=False):
        """
        location is a relative or absolute URI
        publicID if specified will override location as the xml:base
        contextID
        """
        if "#" in location:
            location = URIRef(urldefrag(location)[0])
        publicID = publicID or self.absolutize(location)
        publicID = self.absolutize(publicID, defrag=False)
        context_id = self.context_id(publicID)
        context = self.get_context(context_id, creator=creator)

        absolute_location = self.absolutize(location)
        context.remove((None, None, None))
        if scutter is True and urlparse(absolute_location)[0] == 'http':
            #priorEvent = self.index.value(predicate=SCUTTER.target, object=publicID, any=True)
            priorEvent = self.index.value(predicate=SCUTTER.fetch, object=absolute_location, any=True)
            if priorEvent:
                priorEvent = HTTPGetEvent(self.index, absolute_location, self.log, priorEvent)
                httpStream = urllib2.urlopen(urllib2.Request(absolute_location, headers=priorEvent.createHTTPHeaders()[0]))
                priorEvent.invalidateCache()
                priorEvent.cacheEvent(httpStream, format)
            else:
                newEvent = HTTPGetEvent(self.index, absolute_location, self.log)
                httpStream = urllib2.urlopen(urllib2.Request(absolute_location))
                newEvent.cacheEvent(httpStream, format)
            context.load(httpStream, publicID=publicID, format=format)
            self.scutter(publicID, creator)
        else:
            context.load(absolute_location, publicID=publicID, format=format)

        self.index.remove((context_id, REDFOOT.source, None))
        self.index.add((context_id, REDFOOT.source, location))
        self.index.remove((context_id, REDFOOT.publicID, None))        
        self.index.add((context_id, REDFOOT.publicID, publicID))
        return context

    def get_context(self, identifier, creator=None):
        """ Returns a Context graph for the given identifier, which
        must be a URIRef or BNode."""
        result = super(Redfoot, self).get_context(identifier)
        self.index.remove((identifier, RDF.type, REDFOOT.DeletedContext))
        self.index.add((identifier, RDF.type, REDFOOT.Context))
        if creator and not (identifier, DC_creator, None) in self.index:
            self.index.add((identifier, DC_creator, creator))
        if (identifier, DC_created, None) not in self.index:
            self.index.add((identifier, DC_created, Literal(date_time())))
        return result

    def remove_context(self, identifier):
        """removes both the context and metadata about the context."""
        self.index.remove((identifier, None, None))
        self.index.add((identifier, RDF.type, REDFOOT.DeletedContext))        
        super(Redfoot, self).remove_context(identifier)

    def module(self, subject):
        subject = URIRef(subject)
        if not (subject, None, None) in self:
            self.log.info("importing: %s" % subject)
            try:
                self.load(subject, creator=redfoot_loader.program)
            except Exception, e:
                raise Exception("Error trying to load module for %s\n%s" % (subject, e))
                
        value = self.value(subject)
        assert value!=None, "No objects found for %s, %s" % (subject, RDF.value)

        module_name = subject
        safe_module_name = "subject_%s" % hash(subject)

        module = sys.modules.get(module_name, None)
        if module:
            return module

        module = ModuleType(safe_module_name)
        module.__name__ = module_name 
        module.__file__ = subject
        module.__ispkg__ = 0
        sys.modules[module_name] = module
        code = compile(value+"\n", subject, "exec")
        for key, value in self.__context.items():
            module.__dict__[key] = value
        module.__dict__["__uri__"] = subject

        exec code in module.__dict__
        return sys.modules[module_name]

    def execute(self, code, context=None, **args):
        self.check(code)
        value = self.value(code)
        assert value, "%s has no RDF.value" % code
        assert value.datatype==REDFOOT.Python, "%s RDF.value is not of datatype REDFOOT.Python. %s currently only supports REDFOOT.Python code values" % (code, redfoot_program)
        if context==None:
            context = dict(self.__context)
        for k, v in args.items():
            context[k] = v
        context["redfoot_current"] = code
        context["redfoot_program"] = redfoot_program

        value = value.replace("\r\n", "\n")        
        value = value.replace("\r", "\n")        
        try:
            c = compile(value+"\n", code, "exec")
            exec c in context
        except Exception, e:
            self.log.exception("While trying to exec %s the following exception occurred:\n" % code)
        return context

    def context_id(self, uri, context_id=None):
        """ URI#context """
        uri, frag = urldefrag(uri)
        frag = context_id or frag or "context"
        if frag.startswith("#"):
            frag = frag[1:]
        return URIRef("%s#%s" % (uri, frag))

    def namespace(self, uri, context=None):
        uri = URIRef(uri)
        module = sys.modules.get(uri, None)
        if module is None:
            module = sys.modules[uri] = ModuleType("namespace_%s" % hash(uri))
            module.__name__ = uri 
            module.__file__ = uri
            module.__ispkg__ = 0
            if context is None:
                self.check(uri)
                context_uri = self.context_id(uri)            
                context = self.get_context(context_uri, creator=redfoot_loader.program)            
            d = module.__dict__
            d["NS"] = uri
            # TODO: module.__getattribute__ = module.__dict__.__getitem__ 
            for subject in set(context.subjects(None, None)):
                if subject.startswith(uri):
                    ns, qname = subject.split(uri)
                    d[qname] = subject
        return module

    def bind(self, prefix, namespace, override=True):
        """
        Override Graphs bind to additionally declare the namespace to
        be of RDF.type REDFOOT.Namespce. And to load it if it's not
        already been loaded.
        """
        namespace = URIRef(namespace)
        if not (namespace, RDF.type, REDFOOT.Namespace) in self.index:
            self.check(namespace)             
            self.index.add((namespace, RDF.type, REDFOOT.Namespace))
        super(Redfoot, self).bind(prefix, namespace, override)


    def subclasses(self, uri):
        """
        Applies brute force RDFS entailment to infer additional classification 
        """
        if uri==RDFS.Resource:
            for subclass in self.subjects(RDF.type, RDFS.Class):
                for c in self.objects(subclass, RDFS.subClassOf):
                    if c==RDFS.Resource or not (c, RDF.type, RDFS.Class) in self:
                        yield subclass
                        break
            return
        for subclass in self.subjects(RDFS.subClassOf, uri):
            yield subclass

    def instances(self, uri):
        seen = set()
        for instance in self.subjects(RDF.type, uri):
            if instance not in seen:
                seen.add(instance)
                yield instance
        for subclass in subclasses(self, uri):
            for instance in self.subjects(RDF.type, subclass):
                if instance not in seen:
                    seen.add(instance)
                    yield instance

    def types(self, subject):
	"""
        generator over the types of subject ordered from most specific to least
        Applies brute force RDFS entailment to infer additional classification
        """
	seen = set()
	l = []
	for type in self.objects(subject, RDF.type):
	    for t in self.transitive_objects(type, RDFS.subClassOf):
		num = len(list(self.transitive_objects(t, RDFS.subClassOf)))
		if t not in seen:
		    seen.add(t)
		    l.append((num, t))
        if isinstance(subject, URIRef):
            for type in self.objects(subject.abstract(), RDF.type):
                for t in self.transitive_objects(type, RDFS.subClassOf):
                    num = len(list(self.transitive_objects(t, RDFS.subClassOf)))
                    if t not in seen:
                        seen.add(t)
                        l.append((num, t))
	l.sort()
	l.reverse()
	for num, type in l:
	    yield type

    def possible_properties(self, type):
	for object in self.transitive_objects(type, RDFS.subClassOf):
	    for subject in self.subjects(RDFS.domain, object):
		for property in self.transitive_subjects(RDFS.subPropertyOf, subject): 
		    yield property

    def possible_properties_for_subject(self, subject):
	seen = set()
	for type in chain([RDFS.Resource], self.objects(subject, RDF.type)):
	    for property in self.possible_properties(type):
		if not property in seen:
		    seen.add(property)
		    yield property

    def main(self, options, args):
        program = self.program
        try:
            self.check(program)
        except Exception, e:
            self.log.warning("could not find program for '%s': %s" % (program, e))
        else:
            self.log.info("running: %s ( %s )" % (self.label(program), program))
            self.execute(program, args=args)

    def write(self, s, encoding="utf-8"):
        sys.stdout.write(s.encoding(encoding=encoding))


def add_func(store):
    orig_add = store.add
    def add((s, p, o), context, quoted=False):
        print "add:", s, p, o
        orig_add((s, p, o), context=context, quoted=quoted)
    return add

try:
    redfoot = redfoot_loader.redfoot
except:
    redfoot = Redfoot(redfoot_loader.backend)
    #redfoot.store.add = add_func(redfoot.store)
    redfoot_loader.redfoot = redfoot 
    # NOTE: redfoot_loader is already dealing with opening and closing the backend

from optparse import OptionParser
parser = OptionParser("usage: %prog")
parser.allow_interspersed_args = False

(options, args) = parser.parse_args(args)

redfoot.main(options, args)

]]>
    </rdf:value>
  </redfoot:Kernel>


</rdf:RDF>  
